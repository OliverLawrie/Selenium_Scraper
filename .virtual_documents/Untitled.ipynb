from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
import pandas as pd
import time

# Set up Chrome options
chrome_options = Options()
chrome_options.add_argument("--no-sandbox")
chrome_options.add_argument("--disable-dev-shm-usage")

# Set up ChromeDriver
driver_path = '/Users/oliverlawrie/Desktop/chromedriver-mac-x64/chromedriver'  # Update this path to your chromedriver location
service = Service(driver_path)
driver = webdriver.Chrome(service=service, options=chrome_options)

# Prepare list to store results
results = []

try:
    # Open the Hoopshype player salaries page
    driver.get('https://hoopshype.com/salaries/players/')

    # Wait for the page to load
    time.sleep(10)

    # Click the "Reject Cookies" button if present
    try:
        reject_cookies_button = driver.find_element(By.XPATH, '//button[text()="Reject All"]')  # Modify selector as needed
        reject_cookies_button.click()
        time.sleep(5)  # Wait for the cookie consent to be processed
    except Exception as e:
        print("No cookie consent button found or an error occurred:", e)

    # Scroll down to load all player data
    last_height = driver.execute_script("return document.body.scrollHeight")
    
    while True:
        # Find all player elements on the page
        player_elements = driver.find_elements(By.XPATH, '//div[@class="player-info"]')  # Adjust XPath based on actual HTML structure
        
        print(f"Found {len(player_elements)} player elements on the page.")  # Debugging output

        for element in player_elements:
            try:
                player_name = element.find_element(By.XPATH, './/a[contains(@class, "player-name")]').text
                salary_amount = element.find_element(By.XPATH, './/span[contains(@class, "player-salary")]').text
                results.append({"Player": player_name, "Salary": salary_amount})
            except Exception as e:
                print(f"Error extracting data from element: {e}")

        # Scroll down to load more data
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(5)  # Wait for new data to load

        new_height = driver.execute_script("return document.body.scrollHeight")
        if new_height == last_height:
            break
        last_height = new_height

finally:
    # Close the browser
    driver.quit()

# Convert results to DataFrame and save to CSV in a specific directory
if results:
    df_results = pd.DataFrame(results)
    csv_file_path = '/Users/oliverlawrie/Documents/basketball_player_salaries.csv'  # Update path as needed
    df_results.to_csv(csv_file_path, index=False)
    print(f"Data has been saved to '{csv_file_path}'")
else:
    print("No data was collected.")
